<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Your Name - Professional Profile</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            background-color: #f4f4f4;
            margin: 0;
            padding: 0;
        }
        header {
            background-color: #333;
            color: white;
            text-align: center;
            padding: 50px 20px;
        }
        header h1 {
            margin: 0;
            font-size: 3em;
        }
        header p {
            font-size: 1.2em;
        }
        section {
            max-width: 800px;
            margin: 40px auto;
            padding: 20px;
            background: white;
            border-radius: 8px;
        }
        section h2 {
            color: #333;
            border-bottom: 2px solid #333;
            padding-bottom: 5px;
        }
        .links a {
            display: inline-block;
            margin-right: 10px;
            color: #0066cc;
            text-decoration: none;
        }
        .links a:hover {
            text-decoration: underline;
        }
        footer {
            text-align: center;
            padding: 20px;
            font-size: 0.9em;
            color: #666;
        }
    </style>
</head>
<body>

<header>
    <h1>Anuroop Chinthireddy</h1>
    <p>Data Engineer</p>
</header>

<section>
    <h2>Professional Summary</h2>
    <p>Results-driven Data Engineer with over 3 years of progressive experience designing and implementing scalable, high-performance data solutions across cloud-native and hybrid environments. Proven expertise in ETL/ELT pipeline development, data modeling, and big data processing, with hands-on experience across a broad technology stack including AWS, GCP, Azure, Snowflake, Apache Spark, Airflow, and Databricks.
Proficient in scripting and automation using Python, Scala, and SQL, with a strong foundation in both structured and semi-structured data handling (CSV, JSON, Parquet). Adept at building robust data ingestion pipelines leveraging tools such as AWS Lambda, Glue, Redshift, DynamoDB, and Kafka, supporting real-time and batch processing requirements.
Demonstrated success in optimizing data workflows using Spark transformations, implementing star schema models using Kimball methodology, and enabling advanced analytics through data warehouse solutions in Snowflake and BigQuery. Solid understanding of data governance, encryption, and cloud-based workflow orchestration using Apache Airflow.
Adept in agile environments, delivering high-impact data solutions in cross-functional teams and aligning closely with business stakeholders to deliver actionable insights through BI tools such as Tableau and Power BI. Committed to engineering excellence, continuous integration/deployment (CI/CD), and driving innovation through automation and scalable architectures.
</p>
</section>

<section>
    <h2>Skills</h2>
    <ul>
        <li>Python, SQL, Scala</li>
        <li>Apache Airflow, dbt, Snowflake, Redshift</li>
        <li>AWS, Azure, GCP</li>
        <li>FastAPI, Flask, REST APIs</li>
    </ul>
</section>

<section>
    <h2>Projects</h2>
    <ul>
        <li><strong>Real-Time Data Pipeline:</strong> Built a Kafka-based pipeline for streaming e-commerce data into Snowflake.</li>
        <li><strong>ETL Automation:</strong> Automated financial data extraction and reporting using Airflow + dbt.</li>
    </ul>
</section>

<section>
    <h2>Links</h2>
    <div class="links">
        <a href="https://github.com/yourusername" target="_blank">GitHub</a>
        <a href="https://linkedin.com/in/yourlinkedin" target="_blank">LinkedIn</a>
        <a href="resume.pdf" target="_blank">Resume</a>
    </div>
</section>

<footer>
    &copy; 2025 Your Name. All rights reserved.
</footer>

</body>
</html>
